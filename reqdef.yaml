requirements:
  title: "高速データ処理実践"
  target_audience:
    - 実際にデータ処理をコーディングしたいエンジニア
    - pandas、numpy、PySparkに興味がある方
  duration: 45
  objectives:
    high_level:
      - ローカル環境でのPySparkによるデータ処理の理解と実装
      - AWS Glue上でのPySparkジョブの設定・実行体験
      - Step Functionsを使ったワークフローの構築とSNS通知・S3保存の実演
    detailed:
      - ローカルJupyter NotebookでPySparkを使った統計処理の実装
      - ローカルで動作確認したPySparkコードをAWS Glueに移行し実行する方法の学習
      - Step Functionsによるワークフロー構築、異常検知時のSNS通知および結果のS3保存のデモ

scenario:
  phases:
    Phase1_Recap_and_Overview:
      duration: 10
      steps:
        - "前回の内容を簡単に振り返り、重要ポイントを確認"
          details:
            - "前回学んだ主要な概念や技術スタックを再確認"
        - "本日のセッションの全体構成と流れを再確認"
          details:
            - "各フェーズの目的と進め方を簡潔に説明"

    Phase2_Local_PySpark_Processing:
      duration: 10
      steps:
        - "AWS Glue Studioを開く"
          details:
            - "AWS Glue > Data Integration and ETL > ETL jobs > Notebooks > Start fresh"
            - "必要なノートブックファイルや環境が整っていることを確認"
        - "PySpark環境をセットアップする"
          details:
            - "SparkSessionの作成方法を振り返りつつ、Amazon USのレビューデータセットでのPySpark環境をAWS Glue Studioで構築する"
            - "検証用にAmazon USのレビュー（例: Amazon Reviewデータセットの一部サンプルCSV）をS3に配置し、PySparkのDataFrameで読み込めるか確認"
            - "前回の復習を行う"
        - "PySparkのDataFrameを使ったデータ処理の実装"
          details:
            - "単語の出現頻度を集計する処理を実装する"
            - "pandasとpysparkを比較する"
              - "実際に数十倍の差が出る"
            - "この結果をDynamoDBに入れるのは後で実装する"

    Phase3_Run_on_Glue_Analyse_on_Athena:
      duration: 20
      steps:
        - "Glueのcdkを利用して機能などを解説する"
          details:
            - "AWS CDKを使用してGlueジョブをコードベースで定義する流れを紹介"
            - "CDKプロジェクトのディレクトリ構成や必要なパッケージ（@aws-cdk/aws-glue-alphaなど）を説明"
            - "Glueジョブのリソース定義、IAMロールの付与、ジョブスクリプトのS3デプロイ方法などの概要を解説"
            - "Infrastructure as Codeにより、Glueジョブの設定変更や管理が容易になるメリットを強調"
        - "既にセットアップ済みのAWS Glue環境を利用"
          details:
            - "前もって準備したPySparkスクリプトがGlueジョブとして登録されていることを確認"
        - "Glueジョブを実行する"
          details:
            - "GlueコンソールまたはGlue Studioにアクセスし、対象のジョブを選択"
            - "ジョブを開始し、その実行を監視する"
            - "トリガーではなく手動実行で実行する"
        - "ジョブ実行結果を確認する"
          details:
            - "ジョブの完了を待ち、出力された統計量やログを確認"
            - "parquetでの出力結果を確認する"
        - "Athenaで分析を行う"
          details:
            - "Glueの出力結果をAthenaで分析する"
            - "事前にテーブルを作成し、データの読み込みを行う"
            - "クエリする"

    Phase4_Conclusion:
      duration: 5
      steps:
        - "実践セッションの振り返り"
          details:
            - "今日の学びや重要ポイントをまとめる"
        - "今後の学習のためのリソースや次のステップを紹介"
          details:
            - "参考になるドキュメントやチュートリアルを提示"